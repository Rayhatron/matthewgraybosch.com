---
layout: post
title: "Google Thinks They Can Fix Online Comments with an API? LOL"
description: "Google's &quot;Perspective&quot; is just another high-tech band-aid for a diseased society."
date: 2017-02-23 12:27:01 -0500
image: /assets/images/fullsize/soapbox.jpg
categories: 
  - development
seo:
  type: BlogPosting
options:
  fitvids: true
---
"Never read the comments." You've heard this advice before. Chances are you've had cause to regret ignoring it.

According to the BBC, [Google wants to make it safe to read the comments again](http://www.bbc.com/news/technology-39063863). They've unveiled some new tech called "Perspective" that "uses machine learning to identify problematic comments". It seems Google considers this a sufficiently pressing problem that they have an entire division within the company called Jigsaw that has "a mission to tackle online security dangers such as extremism and cyberbullying".

## How Perspective Probably Works

Though I don't have access to Jigsaw's source code for Perspective, I think I can make an educated guess as to how it works. I think Jigsaw's algorithm for detecting toxic comments is similar to algorithms used in Gmail to detect spam. Gmail's algorithms are refined versions of the [(Naive) Bayesian spam filtering](https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering) techniques recommended by Paul Graham in ["A Plan for Spam (2002)](http://www.paulgraham.com/spam.html) and ["Better Bayesian Filtering" (2003)](http://www.paulgraham.com/better.html).

If I'm right, then Perspective probably isn't as revolutionary as Google's marketing people are likely to make it out to be so they can justify selling comment filtering services to websites at outrageous prices.

However, even if Google charged a flat rate of ten bucks a month for comment filtering, it would still be too much. It would probably be cheaper to just shut down comments altogether. 

That's what I did on my own site because blogs, newspapers, and other online publications shouldn't be in the business of supplying bored randos with soapboxes. If people have something to say about an article or blog post they've read, let them do it on their own blogs or on social media.

## The Real Problem with Perspective

I think there's a bigger and more fundamental issue involved. Perspective strikes me as just [another example of the _solutionism_ that pervades the tech industry](http://www.nytimes.com/2013/03/03/opinion/sunday/the-perils-of-perfection.html), especially in Sillycon Valley. If you've been paywalled, "solutionism" is the tendency among techies to try to solve social problems using technology.

It's hard to blame techies for trying to solve every problem they see with technology. When all you have is a hammer, it's awfully tempting to see every problem as a nail.

However, I'm not convinced that the problem Google wants to solve using Perspective is one that has a technological solution. Sure, it can probably make comment sections less unpleasant to read, but I think Google is treating a symptom, rather than the disease.

The disease is fourfold: 

* Our society is full of people who are both uninformed and opinionated
* Most of these people are young to middle-aged straight white men with internet access
* They have no idea how to argue in a civilized manner, or the ability to judge where and when it is even appropriate to argue
* When challenged, they cling to a profoundly flawed understanding of freedom of speech.

These people think that they have the right to express any ignorant, irrational, or outright vile thought that comes to mind. Within certain legal limits (slander, libel, "fighting words", speech that incites violence) they might even be right. However, it usually isn't legal penalties they face when they go too far. Instead, they get blocked by individuals or get banned from web platforms. In high-profile cases, the social penalty extends to job losses or loss of economic opportunities.

It is hard to sympathize with people whose misuse of their free speech rights gets them blocked, banned, fired, or costs them book deals. They don't understand that right to free speech ends where others' rights to freedom of association begins.

As a result, many of these aggrieved individuals think they're Edgar Friendly in *Demolition Man*, though they more commonly align themselves with Malcolm Reynolds from *Firefly* and *Serenity*. They imagine themselves as embattled crusaders for freedom driven underground by a dystopian left-wing regime where "political correctness" is the first step in a nefarious plan to re-engineer society so that everybody eats at Taco Bell, nobody gets laid, and Hillary Clinton and Jill Stein act as precursors to Doctor Cocteau.

{% include youtube.html src="https://www.youtube.com/embed/bsHsp680nEk" caption="Sylvester Stallone and Denis Leary in *Demolition Man*" %}

I certainly don't want to take away their right to express themselves. I value my own rights too highly for that. However, I understand that while I have the right to speak, I am not entitled to an audience. I certainly don't have the right to make you my captive audience in your own home, on your own website, or in your own social media feed begins.

But that isn't good enough for some people, like those who thought Milo Yiannopoulos was a heroic defender of free speech until he made one joke too many about learning how to give blowjobs in Sunday school. 

These people, who tend to overlap with the alt-reich, _also_ think that their right to speak also means that they have the right to be _heard_. They think they are _entitled_ to platforms on which to express their opinions, no matter how ignorant, irrational, or vile&mdash;and they think they are entitled to treat other people using the same platforms as captive audiences.

## First They Came For the News Sites

This problem is *not* confined to comment sections on news sites. If you're on a social media platform where allowing the public to _read_ your posts also allows the public to _comment_, you run the risk of random anonymous of pseudonymous strangers using your own feed to heap abuse on you. 

If you're a woman, queer, transgender, a person of color, or part of another minority group this probably isn't just a risk but your daily reality. Even if it hasn't happened to you, it may have happened to somebody you know and care about.

And it can always happen to you in the future.

## Why Not Just Block Trolls?

By all means, block trolls. Block them on sight, and without mercy. If somebody's profile looks fake or their avatar or user name comes from an anime or a video game then by all means block them.

However, if you play the blocking game you're playing whack-a-mole. You might get one troll, but if a sufficiently large horde come at you, then you're in deep trouble. They will exhaust your energy and patience, waste your time, and leave you thoroughly demoralized long before you can block them all.

If, instead of blocking trolls you try to be reasonable and simply delete offensive posts, then [you're in for a world of hurt](https://theestablishment.co/when-a-woman-deletes-a-mans-comment-online-4da77027ac60#.n3lismbym). Deleting offensive posts without blocking their authors leaves you open to baseless accusations of censorship by random abusers who don't understand that their comments are nothing but the sort of graffiti one finds on a men's room wall, and therefore unwelcome in most settings.

However, this is also symptomatic of a deeper problem: trolls understand the [Xanatos Gambit](http://tvtropes.org/pmwiki/pmwiki.php/Main/XanatosGambit):

* If you ignore them, they win.
* If you block them, they win.
* If you quit social media in disgust, they win.
* If you shut down your website and scrub every trace of your existence from the internet ([type 3 infocide](http://reagle.org/joseph/pelican/social/infocide-definitions.html)), they win.

The only way to beat a troll is to persuade them to take a good hard look at themselves and understand that they are bullying others as they themselves were bullied. [Most trolls are themselves victims of abuse or of life's random injustices](https://the-orbit.net/brutereason/2015/08/04/what-we-can-learn-from-a-reformed-troll/), and cope with their pain by inflicting pain on others. Lindy West [confronted one of the trolls plaguing her](https://arstechnica.com/business/2015/01/how-an-internet-trolling-victim-bonded-with-her-worst-troll/) and got him to realize the error of his ways, but Ms. West's experience is atypical. Furthermore, it shouldn't be our responsibility to play therapist to every random stranger who tries to cope with their own misery by dragging us down into the shit with them.

## What Should We Do, Then?

This is a social/cultural problem, but Google in their hubris think they can fix it with technology. Well, I can fix abusers with technology, too. I can disable comments on my blog, I can devote the majority of my social media time to platforms like Google+ that let me disable comments on posts, and on less-advanced platforms like Twitter and Facebook I can simply _block abusers on sight_.

I shouldn't have to treat my website or social media feed as a fortress by using tools like Perspective, blocking abusers, or disabling comments on individual posts or site-wide. I shouldn't have to be *on guard* online the way I learned to be in face-to-face interactions after years of being bullied as a child.

I would say that none of us should have to treat the internet as if we were walking alone at night down an unlit street in a rough neighborhood, but that metaphor is faulty because some people *can* walk alone at night down unlit streets in rough neighborhoods without any need to fear for their safety.

Some would also argue that the metaphor above is also faulty because getting insulted, abused, or trolled on the internet isn't the same as getting mugged, raped, or murdered. If I had never been the target of such abuse myself I might say this is true but irrelevant. However, I've had people pull up the WHOIS data for my website, use it to get my phone number, and make threatening phone calls. I've been doxxed. I've had a taste of what some people go through on a daily basis just because they had the nerve to express themselves online despite being women, queer, and/or not white.

I've had a taste, and I didn't like it much. The world should be safe for *everybody*. So should the internet. Using Google's [Perspective API](https://www.perspectiveapi.com/) as a substitute for paying actual human beings to police comment sections and giving them the authority to tell abusive users that they've gone too far (or to ban repeat offenders) is only a half-measure at best.

The real fix is harder, and will take longer. People need to learn some manners. People need to understand that when they post comments on a public forum or on somebody else's website or social media feed that *they are guests*. People need to understand that while they have the right to speak, they are not entitled to either an audience or a platform.

But even these remedies aren't enough. Our society under late-stage capitalism is *diseased*.  We need to create a society where young boys and men aren't encouraged to hide their pain and loneliness and fear until the only way they can cope is by lashing out by trolling or by picking up rifles and committing mass murder. We need to create a society where young people can find a sense of purpose and a reason to live that isn't about "lulz" or winning illusory points from their peers.

## Perspective as a Tool of Prevention

Despite my talk of the need for fundamental societal reforms, Google's [Perspective API](https://www.perspectiveapi.com/) has one potentially beneficial application based on its [experiments](https://www.perspectiveapi.com/#experiments).  While it was the "reading" experiment that made the news by demonstrating the potential of filtering out comments using a sliding toxicity scale, the "reading" experiment is a reactive approach. It hides comments after the fact.

What if we could prevent or at least discourage people from posting toxic comments in the first place? That's where the "writing" experiment comes into play. It asks...

> What if you could see the potential impact of your writing?

We can try to empathize with others and imagine how others might feel as they read our words. We can avoid using harsh language. However, empathy, imagination, and careful word choice only go so far. There's no substitute for data, and here is where Perspective has the opportunity to shine.

You can try the "writing" experiment yourself using small quantities of text, but I wrote this post by feeding individual paragraphs into the experiment and tailoring my language to reduce its toxicity.

If Perspective could be integrated into comment and contact forms, or made available in word processors and text editors as a plugin, individuals can see for themselves the potential impact of their words and make a better-informed decision about how to express themselves. 

Likewise, individual sites could use Perspective to set a maximum acceptable toxicity level, and refuse to permit the submission of comments or posts that exceed the threshold. Freewheeling sites might allow 95-100% toxicity, while sites that want to offer safe spaces can set max toxicity to a much lower value (such as 5-10%).

Google's Perspective may be more useful than I first thought, but it depends on two factors:

* Will Google makes the API publicly and freely available?
* Will developers integrate the Perspective API in a proactive manner rather than a reactive one?

Google alone won't be able to detoxify the Internet with Perspective. While they can create the API and other developers can build it into various tools, it's up to *us* to use these tools to make the Internet a better place.

But what do *I* know? I'm just a dumb programmer. :cat: